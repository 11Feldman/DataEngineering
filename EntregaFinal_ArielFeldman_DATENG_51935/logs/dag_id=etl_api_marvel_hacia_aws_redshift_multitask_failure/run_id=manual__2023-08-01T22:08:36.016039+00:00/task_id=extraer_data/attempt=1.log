[2023-08-01 22:08:38,084] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: etl_api_marvel_hacia_aws_redshift_multitask_failure.extraer_data manual__2023-08-01T22:08:36.016039+00:00 [queued]>
[2023-08-01 22:08:38,099] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: etl_api_marvel_hacia_aws_redshift_multitask_failure.extraer_data manual__2023-08-01T22:08:36.016039+00:00 [queued]>
[2023-08-01 22:08:38,100] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2023-08-01 22:08:38,100] {taskinstance.py:1377} INFO - Starting attempt 1 of 2
[2023-08-01 22:08:38,100] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2023-08-01 22:08:38,122] {taskinstance.py:1397} INFO - Executing <Task(PythonOperator): extraer_data> on 2023-08-01 22:08:36.016039+00:00
[2023-08-01 22:08:38,132] {standard_task_runner.py:52} INFO - Started process 3179 to run task
[2023-08-01 22:08:38,136] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'etl_api_marvel_hacia_aws_redshift_multitask_failure', 'extraer_data', 'manual__2023-08-01T22:08:36.016039+00:00', '--job-id', '1219', '--raw', '--subdir', 'DAGS_FOLDER/dag_etl_multiple_tasks_failure.py', '--cfg-path', '/tmp/tmpq7r211gu', '--error-file', '/tmp/tmp4jj5wjke']
[2023-08-01 22:08:38,138] {standard_task_runner.py:80} INFO - Job 1219: Subtask extraer_data
[2023-08-01 22:08:38,232] {task_command.py:371} INFO - Running <TaskInstance: etl_api_marvel_hacia_aws_redshift_multitask_failure.extraer_data manual__2023-08-01T22:08:36.016039+00:00 [running]> on host 24cbf2f01ed0
[2023-08-01 22:08:38,351] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=arielmfeldman.af@gmail.com
AIRFLOW_CTX_DAG_OWNER=Ariel Feldman
AIRFLOW_CTX_DAG_ID=etl_api_marvel_hacia_aws_redshift_multitask_failure
AIRFLOW_CTX_TASK_ID=extraer_data
AIRFLOW_CTX_EXECUTION_DATE=2023-08-01T22:08:36.016039+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2023-08-01T22:08:36.016039+00:00
[2023-08-01 22:08:39,422] {python.py:173} INFO - Done. Returned value was: None
[2023-08-01 22:08:39,445] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=etl_api_marvel_hacia_aws_redshift_multitask_failure, task_id=extraer_data, execution_date=20230801T220836, start_date=20230801T220838, end_date=20230801T220839
[2023-08-01 22:08:39,515] {local_task_job.py:156} INFO - Task exited with return code 0
[2023-08-01 22:08:39,575] {logging_mixin.py:115} INFO - conf
[2023-08-01 22:08:39,576] {logging_mixin.py:115} INFO - dag
[2023-08-01 22:08:39,576] {logging_mixin.py:115} INFO - dag_run
[2023-08-01 22:08:39,576] {logging_mixin.py:115} INFO - data_interval_end
[2023-08-01 22:08:39,576] {logging_mixin.py:115} INFO - data_interval_start
[2023-08-01 22:08:39,576] {logging_mixin.py:115} INFO - ds
[2023-08-01 22:08:39,576] {logging_mixin.py:115} INFO - ds_nodash
[2023-08-01 22:08:39,576] {logging_mixin.py:115} INFO - execution_date
[2023-08-01 22:08:39,576] {logging_mixin.py:115} INFO - inlets
[2023-08-01 22:08:39,576] {logging_mixin.py:115} INFO - logical_date
[2023-08-01 22:08:39,576] {logging_mixin.py:115} INFO - macros
[2023-08-01 22:08:39,577] {logging_mixin.py:115} INFO - next_ds
[2023-08-01 22:08:39,577] {logging_mixin.py:115} INFO - next_ds_nodash
[2023-08-01 22:08:39,577] {logging_mixin.py:115} INFO - next_execution_date
[2023-08-01 22:08:39,577] {logging_mixin.py:115} INFO - outlets
[2023-08-01 22:08:39,577] {logging_mixin.py:115} INFO - params
[2023-08-01 22:08:39,577] {logging_mixin.py:115} INFO - prev_data_interval_start_success
[2023-08-01 22:08:39,577] {logging_mixin.py:115} INFO - prev_data_interval_end_success
[2023-08-01 22:08:39,577] {logging_mixin.py:115} INFO - prev_ds
[2023-08-01 22:08:39,577] {logging_mixin.py:115} INFO - prev_ds_nodash
[2023-08-01 22:08:39,577] {logging_mixin.py:115} INFO - prev_execution_date
[2023-08-01 22:08:39,578] {logging_mixin.py:115} INFO - prev_execution_date_success
[2023-08-01 22:08:39,578] {logging_mixin.py:115} INFO - prev_start_date_success
[2023-08-01 22:08:39,578] {logging_mixin.py:115} INFO - run_id
[2023-08-01 22:08:39,578] {logging_mixin.py:115} INFO - task
[2023-08-01 22:08:39,578] {logging_mixin.py:115} INFO - task_instance
[2023-08-01 22:08:39,578] {logging_mixin.py:115} INFO - task_instance_key_str
[2023-08-01 22:08:39,578] {logging_mixin.py:115} INFO - test_mode
[2023-08-01 22:08:39,578] {logging_mixin.py:115} INFO - ti
[2023-08-01 22:08:39,578] {logging_mixin.py:115} INFO - tomorrow_ds
[2023-08-01 22:08:39,579] {logging_mixin.py:115} INFO - tomorrow_ds_nodash
[2023-08-01 22:08:39,579] {logging_mixin.py:115} INFO - ts
[2023-08-01 22:08:39,579] {logging_mixin.py:115} INFO - ts_nodash
[2023-08-01 22:08:39,579] {logging_mixin.py:115} INFO - ts_nodash_with_tz
[2023-08-01 22:08:39,579] {logging_mixin.py:115} INFO - var
[2023-08-01 22:08:39,579] {logging_mixin.py:115} INFO - conn
[2023-08-01 22:08:39,579] {logging_mixin.py:115} INFO - yesterday_ds
[2023-08-01 22:08:39,579] {logging_mixin.py:115} INFO - yesterday_ds_nodash
[2023-08-01 22:08:39,579] {logging_mixin.py:115} INFO - extraer_data
[2023-08-01 22:08:39,580] {logging_mixin.py:115} INFO - etl_api_marvel_hacia_aws_redshift_multitask_failure
[2023-08-01 22:08:39,580] {logging_mixin.py:115} INFO - 2023-08-01 22:08:36.016039+00:00
[2023-08-01 22:08:39,580] {logging_mixin.py:115} INFO - 2023-08-01 22:08:38.084423+00:00
[2023-08-01 22:08:39,580] {logging_mixin.py:115} INFO - 2023-08-01 22:08:39.445791+00:00
[2023-08-01 22:08:39,580] {logging_mixin.py:115} INFO - 1.361368
[2023-08-01 22:08:39,580] {logging_mixin.py:115} INFO - PythonOperator
[2023-08-01 22:08:39,580] {logging_mixin.py:115} INFO - 3
[2023-08-01 22:08:39,588] {logging_mixin.py:115} INFO - (Index('ti_dag_state', Column('dag_id', String(length=250), ForeignKey('dag_run.dag_id'), table=<task_instance>, primary_key=True, nullable=False), Column('state', String(length=20), table=<task_instance>)), Index('ti_dag_run', Column('dag_id', String(length=250), ForeignKey('dag_run.dag_id'), table=<task_instance>, primary_key=True, nullable=False), Column('run_id', String(length=250), ForeignKey('dag_run.run_id'), table=<task_instance>, primary_key=True, nullable=False)), Index('ti_state', Column('state', String(length=20), table=<task_instance>)), Index('ti_state_lkp', Column('dag_id', String(length=250), ForeignKey('dag_run.dag_id'), table=<task_instance>, primary_key=True, nullable=False), Column('task_id', String(length=250), table=<task_instance>, primary_key=True, nullable=False), Column('run_id', String(length=250), ForeignKey('dag_run.run_id'), table=<task_instance>, primary_key=True, nullable=False), Column('state', String(length=20), table=<task_instance>)), Index('ti_pool', Column('pool', String(length=256), table=<task_instance>, nullable=False), Column('state', String(length=20), table=<task_instance>), Column('priority_weight', Integer(), table=<task_instance>)), Index('ti_job_id', Column('job_id', Integer(), table=<task_instance>)), Index('ti_trigger_id', Column('trigger_id', BigInteger(), ForeignKey('trigger.id'), table=<task_instance>)), ForeignKeyConstraint(<sqlalchemy.sql.base.DedupeColumnCollection object at 0x7f10033f7530>, None, name='task_instance_trigger_id_fkey', ondelete='CASCADE', table=Table('task_instance', MetaData(), Column('task_id', String(length=250), table=<task_instance>, primary_key=True, nullable=False), Column('dag_id', String(length=250), ForeignKey('dag_run.dag_id'), table=<task_instance>, primary_key=True, nullable=False), Column('run_id', String(length=250), ForeignKey('dag_run.run_id'), table=<task_instance>, primary_key=True, nullable=False), Column('map_index', Integer(), table=<task_instance>, primary_key=True, nullable=False, server_default=DefaultClause(<sqlalchemy.sql.elements.TextClause object at 0x7f1003a55590>, for_update=False)), Column('start_date', UtcDateTime(timezone=True), table=<task_instance>), Column('end_date', UtcDateTime(timezone=True), table=<task_instance>), Column('duration', Float(), table=<task_instance>), Column('state', String(length=20), table=<task_instance>), Column('try_number', Integer(), table=<task_instance>, default=ColumnDefault(0)), Column('max_tries', Integer(), table=<task_instance>), Column('hostname', String(length=1000), table=<task_instance>), Column('unixname', String(length=1000), table=<task_instance>), Column('job_id', Integer(), table=<task_instance>), Column('pool', String(length=256), table=<task_instance>, nullable=False), Column('pool_slots', Integer(), table=<task_instance>, nullable=False, default=ColumnDefault(1), server_default=DefaultClause(<sqlalchemy.sql.elements.TextClause object at 0x7f1003a55b10>, for_update=False)), Column('queue', String(length=256), table=<task_instance>), Column('priority_weight', Integer(), table=<task_instance>), Column('operator', String(length=1000), table=<task_instance>), Column('queued_dttm', UtcDateTime(timezone=True), table=<task_instance>), Column('queued_by_job_id', Integer(), table=<task_instance>), Column('pid', Integer(), table=<task_instance>), Column('executor_config', PickleType(), table=<task_instance>), Column('external_executor_id', String(length=250), table=<task_instance>), Column('trigger_id', BigInteger(), ForeignKey('trigger.id'), table=<task_instance>), Column('trigger_timeout', UtcDateTime(timezone=True), table=<task_instance>), Column('next_method', String(length=1000), table=<task_instance>), Column('next_kwargs', ExtendedJSON(), table=<task_instance>), schema=None)), ForeignKeyConstraint(<sqlalchemy.sql.base.DedupeColumnCollection object at 0x7f10033f7710>, None, name='task_instance_dag_run_fkey', ondelete='CASCADE', table=Table('task_instance', MetaData(), Column('task_id', String(length=250), table=<task_instance>, primary_key=True, nullable=False), Column('dag_id', String(length=250), ForeignKey('dag_run.dag_id'), table=<task_instance>, primary_key=True, nullable=False), Column('run_id', String(length=250), ForeignKey('dag_run.run_id'), table=<task_instance>, primary_key=True, nullable=False), Column('map_index', Integer(), table=<task_instance>, primary_key=True, nullable=False, server_default=DefaultClause(<sqlalchemy.sql.elements.TextClause object at 0x7f1003a55590>, for_update=False)), Column('start_date', UtcDateTime(timezone=True), table=<task_instance>), Column('end_date', UtcDateTime(timezone=True), table=<task_instance>), Column('duration', Float(), table=<task_instance>), Column('state', String(length=20), table=<task_instance>), Column('try_number', Integer(), table=<task_instance>, default=ColumnDefault(0)), Column('max_tries', Integer(), table=<task_instance>), Column('hostname', String(length=1000), table=<task_instance>), Column('unixname', String(length=1000), table=<task_instance>), Column('job_id', Integer(), table=<task_instance>), Column('pool', String(length=256), table=<task_instance>, nullable=False), Column('pool_slots', Integer(), table=<task_instance>, nullable=False, default=ColumnDefault(1), server_default=DefaultClause(<sqlalchemy.sql.elements.TextClause object at 0x7f1003a55b10>, for_update=False)), Column('queue', String(length=256), table=<task_instance>), Column('priority_weight', Integer(), table=<task_instance>), Column('operator', String(length=1000), table=<task_instance>), Column('queued_dttm', UtcDateTime(timezone=True), table=<task_instance>), Column('queued_by_job_id', Integer(), table=<task_instance>), Column('pid', Integer(), table=<task_instance>), Column('executor_config', PickleType(), table=<task_instance>), Column('external_executor_id', String(length=250), table=<task_instance>), Column('trigger_id', BigInteger(), ForeignKey('trigger.id'), table=<task_instance>), Column('trigger_timeout', UtcDateTime(timezone=True), table=<task_instance>), Column('next_method', String(length=1000), table=<task_instance>), Column('next_kwargs', ExtendedJSON(), table=<task_instance>), schema=None)))
[2023-08-01 22:08:42,855] {logging_mixin.py:115} INFO - Exito
[2023-08-01 22:08:42,876] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
