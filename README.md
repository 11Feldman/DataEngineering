# CoderHouse
## Data Engineering
### Repositorio de ejercicios de CoderHouse 

[![Made withJupyter](https://img.shields.io/badge/Made%20with-Jupyter-orange?style=for-the-badge&logo=Jupyter)](https://jupyter.org/try)

[![forthebadge made-with-python](http://ForTheBadge.com/images/badges/made-with-python.svg)](https://www.python.org/)

[![GitHub commits](https://img.shields.io/github/commits-since/Naereen/StrapDown.js/v1.0.0.svg)](https://GitHub.com/Naereen/StrapDown.js/commit/)

[![GitHub latest commit](https://badgen.net/github/last-commit/Naereen/Strapdown.js)](https://GitHub.com/Naereen/StrapDown.js/commit/)

[![GitHub forks](https://img.shields.io/github/forks/Naereen/StrapDown.js.svg?style=social&label=Fork&maxAge=2592000)](https://GitHub.com/Naereen/StrapDown.js/network/)

[![GitHub forks](https://badgen.net/github/forks/Naereen/Strapdown.js/)](https://GitHub.com/Naereen/StrapDown.js/network/)

[![Naereen's top languages](https://github-readme-stats.vercel.app/api/top-langs/?username=Naereen&theme=blue-green)](https://github.com/anuraghazra/github-readme-stats)

[![DenverCoder1's github streak](https://github-readme-streak-stats.herokuapp.com/?user=Naereen&theme=blue-green)](https://github.com/DenverCoder1/github-readme-streak-stats)


#### Entregable 1:
+ A. Se debe conectar a una Api publica para extraer datos
+ B. Crear tablas en Redshift.
+ C. Insertar datos en Redshift.

Se toman datos de la api de marvel https://developer.marvel.com/.

Para este caso las credenciales no se suben y quedan de manera local en un archivo ".py" tambien se genero uno igual como ".env", pero para el caso
se uso los del ".py"
En estos archivos se encuentran.
Las claves publicas y privadas, el hash generado, y los datos de conexion hacia aws.

#### Entregable 2:

+ A. Se debe conectar a una Api publica para extraer datos
+ B. Crear tablas en Redshift.
+ C. Verificar si hay duplicados con Pandas.
+ C. Insertar datos desde un data frame en Redshift.

Se toman datos de la api de marvel https://developer.marvel.com/.

Para este caso las credenciales no se suben y quedan de manera local en un archivo ".py" tambien se genero uno igual como ".env", pero para el caso
se uso los del ".py"
En estos archivos se encuentran.
Las claves publicas y privadas, el hash generado, y los datos de conexion hacia aws.

#### Entregable 3:

Utilizando AirFlow

+ A. Se debe conectar a una Api publica para extraer datos
+ B. Crear tablas en Redshift.
+ C. Verificar si hay duplicados con Pandas.
+ C. Insertar datos desde un data frame en Redshift.

Se toman datos de la api de marvel https://developer.marvel.com/.
Para este caso se usa AirFlow:
Usando DAGS, Operadores, Tareas y XCOMs.
Apache Airflow se levanta con un docker-compose.
Las credenciales a la api y las variables de conexion a AWS se encuentran en la configuracion de AirFlow para mantenerlas de manera secreta y encriptadas.


<!-- 
## Comenzando üöÄ

_Estas instrucciones te permitir√°n obtener una copia del proyecto en funcionamiento en tu m√°quina local para prop√≥sitos de desarrollo y pruebas._

Mira **Deployment** para conocer como desplegar el proyecto.


### Pre-requisitos üìã

_Que cosas necesitas para instalar el software y como instalarlas_

```
Da un ejemplo
```
<!-- 
### Instalaci√≥n üîß

_Una serie de ejemplos paso a paso que te dice lo que debes ejecutar para tener un entorno de desarrollo ejecutandose_

_D√≠ c√≥mo ser√° ese paso_

```
Da un ejemplo
```

_Y repite_

```
hasta finalizar
```

_Finaliza con un ejemplo de c√≥mo obtener datos del sistema o como usarlos para una peque√±a demo_

## Ejecutando las pruebas ‚öôÔ∏è

_Explica como ejecutar las pruebas automatizadas para este sistema_

### Analice las pruebas end-to-end üî©

_Explica que verifican estas pruebas y por qu√©_

```
Da un ejemplo
```

### Y las pruebas de estilo de codificaci√≥n ‚å®Ô∏è

_Explica que verifican estas pruebas y por qu√©_

```
Da un ejemplo
```

## Despliegue üì¶ -->

<!-- _Agrega notas adicionales sobre como hacer deploy_ -->

## Construido con üõ†Ô∏è

<!-- _Menciona las herramientas que utilizaste para crear tu proyecto_ -->

* [Airflow](https://airflow.apache.org/) - plataforma creada por la comunidad para crear, programar y monitorear flujos de trabajo mediante programaci√≥n.
* [Python](https://www.python.org/) - Tecnologia utilizada para el proyecto
* [Docker](https://www.docker.com/) - Usado para generar el docker-compose
* [API MARVEL](https://developer.marvel.com/) - Se utiliza esta api para extraer informacion
* [AWS Redshift](https://aws.amazon.com/es/redshift/) - Base de datos utilizada para leer y cargar datos.
* [Pandas](https://pandas.pydata.org/) - Tecnologia utilizada para el proyecto
* [PySpark](https://spark.apache.org/docs/latest/api/python/) - Tecnologia utilizada para el proyecto
* [Jupyter Notebook](https://jupyter.org/) - Tecnologia utilizada para el proyecto
* [VSC](https://code.visualstudio.com/) - IDLE utilizado para el proyecto.



<!-- 
## Contribuyendo üñáÔ∏è

Por favor lee el [CONTRIBUTING.md](https://gist.github.com/villanuevand/xxxxxx) para detalles de nuestro c√≥digo de conducta, y el proceso para enviarnos pull requests. -->

<!-- ## Wiki üìñ

Puedes encontrar mucho m√°s de c√≥mo utilizar este proyecto en nuestra [Wiki](https://github.com/tu/proyecto/wiki) -->

## Versionado üìå

Para todas las versiones disponibles, mira los [tags en este repositorio](https://github.com/11Feldman/DataEngineering/tags).

## Autores ‚úíÔ∏è

* **Ariel Feldman** - *Trabajo Inicial* - [feldmanam](https://github.com/feldman11)

<!-- Tambi√©n puedes mirar la lista de todos los [contribuyentes](https://github.com/your/project/contributors) qu√≠enes han participado en este proyecto.  -->

## Licencia üìÑ

[![Open Source? Yes!](https://badgen.net/badge/Open%20Source%20%3F/Yes%21/blue?icon=github)](https://github.com/Naereen/badges/) Este proyecto se encuentra open source
<!-- Este proyecto est√° bajo la Licencia (Tu Licencia) - mira el archivo [LICENSE.md](LICENSE.md) para detalles -->
